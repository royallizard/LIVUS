{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e93c52e-fe3f-4871-a224-367101e279e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Function to split file name into components - operating system, name, and version\n",
    "def split_file_name(file_name):\n",
    "    split_name = file_name.split('_')\n",
    "    version = split_name[1]\n",
    "    split_name = split_name[0].split('-')\n",
    "    os = split_name[0]\n",
    "    name = split_name[1]\n",
    "    return os, name, version\n",
    "\n",
    "# Load and prepare training data\n",
    "# training and testing data has been cleaned before usage \n",
    "file_dir = \"../data/training\"\n",
    "corpus = []\n",
    "file_names = []\n",
    "\n",
    "# iterate over files in training directory\n",
    "for file in os.listdir(file_dir):\n",
    "    if file.endswith('.txt'):\n",
    "        file_path = os.path.join(file_dir, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            contents = f.read()\n",
    "            corpus.append(contents)\n",
    "            file_names.append(file[:-4])  # storing filename without .txt extension\n",
    "\n",
    "# Create a TfidfVectorizer and transform the corpus\n",
    "vectorizer = TfidfVectorizer(token_pattern='.+', max_df=0.7)\n",
    "\n",
    "feature_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(feature_matrix, file_names) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4519691e-0d7d-493c-8227-cf9d8d583f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for wireshark:\n",
      "                  Prediction  Probability\n",
      "0            libexpat.so.1.6         0.20\n",
      "1         libdvdcss.so.2.2.0         0.18\n",
      "2                    liblzo2         0.16\n",
      "3      libgnutls-xssl.so.0.0         0.14\n",
      "4  libgnutls-openssl.so.13.3         0.07\n",
      "5                    liblzma         0.07\n",
      "\n",
      "Results for vlc:\n",
      "                  Prediction  Probability\n",
      "0            libexpat.so.1.6         0.26\n",
      "1         libdvdcss.so.2.2.0         0.19\n",
      "2                    liblzo2         0.13\n",
      "3      libgnutls-xssl.so.0.0         0.12\n",
      "4  libgnutls-openssl.so.13.3         0.07\n",
      "5        libpng16.so.16.37.0         0.07\n",
      "\n",
      "Results for openttd:\n",
      "                  Prediction  Probability\n",
      "0            libexpat.so.1.6         0.21\n",
      "1         libdvdcss.so.2.2.0         0.16\n",
      "2      libgnutls-xssl.so.0.0         0.15\n",
      "3                    liblzo2         0.15\n",
      "4  libgnutls-openssl.so.13.3         0.08\n",
      "\n",
      "Results for gimp-2.10:\n",
      "                  Prediction  Probability\n",
      "0            libexpat.so.1.6         0.24\n",
      "1         libdvdcss.so.2.2.0         0.17\n",
      "2      libgnutls-xssl.so.0.0         0.15\n",
      "3                    liblzo2         0.14\n",
      "4  libgnutls-openssl.so.13.3         0.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare testing data\n",
    "test_dir = \"../data/testing\"\n",
    "test_corpus = []\n",
    "test_file_names = []\n",
    "\n",
    "# Iterate over files in testing directory\n",
    "for file in os.listdir(test_dir):\n",
    "    if file.endswith('.txt'):\n",
    "        file_path = os.path.join(test_dir, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            contents = f.read()\n",
    "            test_corpus.append(contents)\n",
    "            test_file_names.append(file[:-4])  # storing filename without .txt extension\n",
    "\n",
    "# Transform the test corpus using the trained vectorizer\n",
    "feature_matrix = vectorizer.transform(test_corpus)\n",
    "\n",
    "# Define the threshold for prediction\n",
    "threshold = 0.07\n",
    "\n",
    "# Initialize a list to store the results for each test file\n",
    "results = []\n",
    "\n",
    "# Get the predictions for each test file\n",
    "for i in range(len(test_file_names)):\n",
    "    file_name = test_file_names[i]\n",
    "    prediction_scores = clf.predict_proba(feature_matrix[i])[0]  # Get the prediction probabilities\n",
    "    predictions = [(clf.classes_[j], score) for j, score in enumerate(prediction_scores) if score >= threshold]\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)  # Sort predictions by probability in descending order\n",
    "    results.append((file_name, predictions))\n",
    "\n",
    "# Print the results in table format for each test file\n",
    "for file_name, predictions in results:\n",
    "    df = pd.DataFrame(predictions, columns=['Prediction', 'Probability'])\n",
    "    print(f\"Results for {file_name}:\")\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc85d7e2-ca93-4296-905c-01e76a6efced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ../data/target_file/openttd:\n",
      "                  Prediction  Probability\n",
      "0            libexpat.so.1.6         0.21\n",
      "1         libdvdcss.so.2.2.0         0.16\n",
      "2      libgnutls-xssl.so.0.0         0.15\n",
      "3                    liblzo2         0.15\n",
      "4  libgnutls-openssl.so.13.3         0.08\n",
      "5                    liblzma         0.06\n",
      "6        libpng16.so.16.37.0         0.05\n",
      "7             libtiff.so.5.2         0.05\n",
      "Now searching NVD for the predicted libraries...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Desktop/MA/LIVUS/src/../util/parse_nvd.py\", line 110, in <module>\n",
      "    main()\n",
      "  File \"/home/user/Desktop/MA/LIVUS/src/../util/parse_nvd.py\", line 84, in main\n",
      "    save_json_data(file_path, json_data)\n",
      "  File \"/home/user/Desktop/MA/LIVUS/src/../util/parse_nvd.py\", line 28, in save_json_data\n",
      "    if os.path.exists(file_path):\n",
      "NameError: name 'os' is not defined\n"
     ]
    }
   ],
   "source": [
    "folder_path = '../data/target_file/'\n",
    "output_file = f'../out/{target_file_name}.txt'\n",
    "output_prediction = f'../out/{target_file_name}_predictions.txt'\n",
    "threshold = 0.05  # Set your desired threshold value\n",
    "\n",
    "# Get the list of files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Select the first file in the folder\n",
    "if files:\n",
    "    target_file_name = files[0]\n",
    "    input_file = os.path.join(folder_path, files[0])\n",
    "else:\n",
    "    print(\"../data/input_folder/ is empty. Please add a file to apply LIVUS to.\")\n",
    "    exit(1)\n",
    "\n",
    "# Run the 'strings' command on the input file and capture the output\n",
    "output = subprocess.check_output(['strings', input_file]).decode('utf-8')\n",
    "\n",
    "# Save the output as the predicted library in the specified output file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output)\n",
    "\n",
    "# Read the contents of the document\n",
    "with open(output_file, 'r', encoding='utf-8') as f:\n",
    "    val_contents = f.read()\n",
    "\n",
    "val_feature_matrix = vectorizer.transform([val_contents])\n",
    "prediction_scores = clf.predict_proba(val_feature_matrix)[0]  # Get the prediction probabilities\n",
    "\n",
    "# Get predictions above the threshold\n",
    "predictions = [(clf.classes_[i], score) for i, score in enumerate(prediction_scores) if score >= threshold]\n",
    "predictions.sort(key=lambda x: x[1], reverse=True)  # Sort predictions by probability in descending order\n",
    "\n",
    "# Print the results in table format and write predictions to output prediction file\n",
    "df = pd.DataFrame(predictions, columns=['Prediction', 'Probability'])\n",
    "print(f\"Results for {input_file}:\")\n",
    "print(df)\n",
    "\n",
    "# Clear names after printing and write predictions to output prediction file\n",
    "cleaned_predictions = [prediction[0].split('.')[0] for prediction in predictions]\n",
    "with open(output_prediction, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(cleaned_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b6b03e-50d7-4da2-862b-2d6d87632a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now searching NVD for the predicted libraries...\n",
      "Searching for libexpat...\n",
      "Updated CVE file for libexpat\n",
      "Processing the CVE data...\n",
      "Saved to file\n",
      "Searching for libdvdcss...\n",
      "No vulnerabilities found for libdvdcss.\n",
      "Searching for libgnutls-xssl...\n",
      "No vulnerabilities found for libgnutls-xssl.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now searching NVD for the predicted libraries...\")\n",
    "stream = os.popen('python3 ../util/parse_nvd.py')\n",
    "output = stream.read()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b8511-ea12-4dcd-afa4-a8b02d190693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
